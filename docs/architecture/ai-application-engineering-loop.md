# AI 应用工程师方法论闭环（Application Engineering Loop）

> 本文档用于说明：**我如何将不稳定的大模型能力，工程化为可执行、可验证、可持续演进的 AI 应用系统。**  
> 这是一个应用工程问题，而不是模型研究问题。

---

## 1. 问题定位：我解决的是什么问题？

我关注的不是：
- 模型训练 / 微调
- 算法指标（BLEU / ROUGE / perplexity）
- 学术型 NLP 研究

而是以下 **应用工程问题**：

- 如何把 LLM 的“文本生成能力”转化为 **可执行决策**
- 如何让模型输出 **稳定地驱动代码**
- 如何在模型不确定的前提下，保证系统 **可回放、可验证**

一句话定位：

> **我是 AI 应用工程师，而不是模型研究者。**

---

## 2. 核心工程闭环（Application Engineering Loop）

我采用的 AI 应用工程闭环如下：

```
用户输入 / 需求
   ↓
LLM 生成结构化计划（Plan JSON）
   ↓
Plan Executor（逐步执行）
   ↓
Tool Registry（工具注册与分发）
   ↓
Tool 执行（成功 / 失败）
   ↓
execution_results 聚合
   ↓
最终 JSON 输出 / Sample 落盘
   ↓
Docs + Verification + Samples
   ↺（反馈到下一轮改进）
```

该闭环的目标是：

- **任何一次执行都可以被复现**
- **任何一次失败都有明确结构化原因**
- **系统行为不依赖人工解释**

---

## 3. 关键设计原则

### 3.1 模型只“想”，代码负责“做”

- 模型职责：
  - 生成计划
  - 决定调用哪个工具
- 代码职责：
  - 执行工具
  - 校验参数
  - 捕获错误
  - 聚合结果

> 模型不可直接产生副作用，所有副作用必须通过 Tool。

---

### 3.2 所有中间态必须是 JSON-safe

- Plan
- Tool arguments
- Tool output
- execution_results
- 最终 payload

全部以 JSON-safe 数据结构表达，确保：

- 可落盘
- 可 diff
- 可回放

---

### 3.3 成功路径与失败路径同等重要

系统必须显式支持以下情况：

- 工具不存在
- 参数缺失 / 类型错误
- 工具执行异常

失败不是“异常状态”，而是 **一等公民**。

---

## 4. 不稳定的 AI，如何变成稳定的工程系统？

我的解决方式不是“让模型更聪明”，而是：

- 用 **结构** 约束模型
- 用 **代码** 兜底模型
- 用 **文档与样例** 固化行为

具体体现在：

- `docs/guide/verification.md`：回归与验收清单
- `docs/samples/`：真实运行样例
- `--debug` 模式：完整 payload 输出

---

## 5. 我如何与 AI 协作（而不被 AI 带跑）

我不会把 AI 当作“替我思考一切的黑盒”，  
而是作为 **工程协作对象**。

协作方式已固化为协议文档：

👉 `docs/guide/how-to-work-with-ai.md`

该协议明确了：
- AI 的角色
- 工程约束
- 输出边界
- 不确定性处理方式

---

## 6. 该工程闭环如何扩展（路线图）

在当前单 Agent / 单 Tool 闭环稳定后，可逐步扩展：

- 新工具：
  - `read_file_tool`
  - `write_file_tool`
  - `http_fetch_tool`
- 多步骤 Plan
- 多 Agent 协作（保持执行链路不变）

扩展遵循同一原则：

> **不破坏闭环，只扩展节点。**

---

## 7. 总结

我构建的不是一个 Demo，  
而是一套 **可长期演进的 AI 应用工程方法论**：

- 有清晰的职责边界
- 有稳定的执行模型
- 有可验证的工程事实
- 有可复用的协作协议

这套方法论使得 AI 能力：
- 可控
- 可审计
- 可扩展

---

（完）
